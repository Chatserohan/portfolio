{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame = cv2.resize(frame,(224,224))\n",
    "    y_pred = detect_face_mask(frame) \n",
    "    print(y_pred) \n",
    "\n",
    "    if y_pred == 0:\n",
    "        draw_label(frame, 'mask', (30,30), (0,255,0))\n",
    "    else:\n",
    "        draw_label(frame, 'no mask', (30,30), (0,0,255))\n",
    "\n",
    "    cv2.imshow('window',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "\n",
    "        break \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetect_face_mask(img):\n",
    "\n",
    "    y_pred = model.predict_classes(img.reshape(1,224,224,3))\n",
    "    return y_pred \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = cv2.imread('image.jpg')\n",
    "sample1 = cv2.resize(sample1, (224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(img,text, pos,bg_color):\n",
    "    test_size = cv2.getTextSize(text, cv2.FONT_HERSHLY_SIMPLEX, 1, cv2.FILLED)\n",
    "    end_x = pos[0] + text_size[0][0] + 2 \n",
    "    end_y = pos[] + text_size[0][1] + 2\n",
    "\n",
    "    cv2.rectangle(img, pos,(end_x, end_y), bg_color, cv2.FILLED)\n",
    "    cv2.putText(img, text, cv2.FONT_HERSHLY_SIMPLEX, 1, (0,0,0),cv2.LINE_AA)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:58:12.573256: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-11-16 12:58:12.885157: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-11-16 12:58:13.022700: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:58:16.184905: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models  import load_model \n",
    "model = load_model('mask_detector.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:57:59.767691: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-16 12:58:00.729729: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-16 12:58:02.779748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'WhatsApp Image 2024-10-27 at 00.30.26.jpeg'  # Replace with your image path\n",
    "img = image.load_img(img_path, target_size=(224, 224))  # Resize to the target size\n",
    "img_array = image.img_to_array(img)  # Convert image to a NumPy array\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension (required for prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 470ms/step\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "predict = model.predict(img_array)\n",
    "\n",
    "predictions = np.array(predict)  \n",
    "predicted_class = (predictions >= 0.5).astype(int)  # Threshold at 0.5\n",
    "print(predicted_class)  # Output will be 0 or 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img_path = img_path  # Replace with your image path\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # Resize to the target size\n",
    "    img_array = image.img_to_array(img)  # Convert image to a NumPy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    predict = model.predict(img_array)\n",
    "    predictions = np.array(predict)  \n",
    "    predicted_class = (predictions >= 0.5).astype(int)  # Threshold at 0.5\n",
    "    \n",
    "    return predicted_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 950ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('mask1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy on camera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "def predict(frame):\n",
    "    # Resize the frame to the required input size for the model\n",
    "    img = image.array_to_img(frame)  # Convert NumPy array to a PIL Image\n",
    "    img = img.resize((224, 224))  # Resize to the target size for the model\n",
    "    \n",
    "    # Convert image to a NumPy array and preprocess\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    # img_array = img_array / 255.0  # Normalize if required by your model\n",
    "\n",
    "    # Predict\n",
    "    predict = model.predict(img_array)\n",
    "    predictions = np.array(predict)  # Convert to a NumPy array if needed\n",
    "    predicted_class = (predictions >= 0.5).astype(int)  # Binary thresholding\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deployable function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 12:58:51.738410: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 733ms/step\n",
      "1/1 [==============================] - 1s 613ms/step\n",
      "1/1 [==============================] - 1s 562ms/step\n",
      "1/1 [==============================] - 1s 561ms/step\n",
      "1/1 [==============================] - 1s 617ms/step\n",
      "1/1 [==============================] - 1s 613ms/step\n",
      "1/1 [==============================] - 1s 626ms/step\n",
      "1/1 [==============================] - 1s 642ms/step\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 1s 720ms/step\n",
      "1/1 [==============================] - 1s 786ms/step\n",
      "1/1 [==============================] - 1s 783ms/step\n",
      "1/1 [==============================] - 1s 800ms/step\n",
      "1/1 [==============================] - 1s 766ms/step\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "1/1 [==============================] - 1s 824ms/step\n",
      "1/1 [==============================] - 1s 770ms/step\n",
      "1/1 [==============================] - 1s 858ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load your pre-trained mask detection model\n",
    "model = tf.keras.models.load_model('mask_detector.h5')  # Replace with your model path\n",
    "\n",
    "# Open the default camera (index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Function to predict mask detection on a frame\n",
    "def predict(frame):\n",
    "    \"\"\"\n",
    "    Predict whether the person is wearing a mask or not from the frame.\n",
    "    \n",
    "    Parameters:\n",
    "    - frame: A single frame from the camera (NumPy array).\n",
    "\n",
    "    Returns:\n",
    "    - predicted_class: 1 for \"Mask Detected\", 0 for \"No Mask Detected\".\n",
    "    \"\"\"\n",
    "    # Resize the frame to 224x224 for model input (assuming model expects 224x224 images)\n",
    "    img_resized = cv2.resize(frame, (224, 224))  # Resize frame to match model input\n",
    "    \n",
    "    # Convert the image to a NumPy array and preprocess it\n",
    "    img_array = image.img_to_array(img_resized)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize the image if the model was trained with this normalization\n",
    "\n",
    "    # Make the prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    \n",
    "    # Return the predicted class based on the threshold (0.5 for binary classification)\n",
    "    predicted_class = (prediction >= 0.5).astype(int)\n",
    "    return predicted_class[0][0]  # Return the class (0 or 1)\n",
    "\n",
    "frame_counter = 0\n",
    "skip_frames = 1  # Skip every 3rd frame to speed up processing\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Skip frames to improve performance\n",
    "    if frame_counter % skip_frames == 0:\n",
    "        # Make a prediction on the current frame\n",
    "        predicted_class = predict(frame)\n",
    "\n",
    "        # Display the predicted class on the frame\n",
    "        if predicted_class == 1:\n",
    "            label = 'NO Mask Detected'\n",
    "            color = (0, 0, 255)  # Green color for \"Mask\"\n",
    "        else:\n",
    "            label = 'Mask Detected'\n",
    "            color = (0, 255, 0)  # Red color for \"No Mask\"\n",
    "\n",
    "        # Display the label on the frame (top-left corner)\n",
    "        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame with the prediction\n",
    "    cv2.imshow('Live Camera Feed', frame)\n",
    "\n",
    "    frame_counter += 1  # Increment frame counter\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
